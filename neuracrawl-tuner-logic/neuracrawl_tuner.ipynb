{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1fd78753",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# neuracrawl-tuner\n",
    "# Import all functionality from the library module\n",
    "\n",
    "from neuracrawl_tuner_lib import (\n",
    "    PROJECT_MANAGER,\n",
    "    save_sitemap_urls,\n",
    "    extract_frequent_sitemap_urls,\n",
    "    extract_url_extensions,\n",
    "    extract_url_regexes,\n",
    "    extract_interesting_urls,\n",
    "    download_interesting_urls,\n",
    "    extract_css_selectors,\n",
    "    apply_css_selectors,\n",
    "    discover_urls,\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "791a4023",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== CUSTOMER NAME =====\n",
    "CUSTOMER = \"neuraflow\"\n",
    "# =====================================\n",
    "\n",
    "# Derived paths\n",
    "DOMAIN_URL = f\"https://www.{CUSTOMER}.de\"\n",
    "LOG_FILE = f\"{CUSTOMER}_discovery.log\"\n",
    "\n",
    "PROJECT_MANAGER.set_project(CUSTOMER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42ddcfc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from nest_asyncio import apply\n",
    "apply()\n",
    "\n",
    "\n",
    "\n",
    "result = await discover_urls(\n",
    "    DOMAIN_URL,\n",
    "    max_pages=5000,\n",
    "    url_exclusion_patterns=[\n",
    "        r\"(aktuelles|meldungen|veranstaltungen-details|event|currentPage|dachauer-volksblatt|/dokumente/)\",\n",
    "        r\"\\.(ics|pdf|json|vcf|kml|gpx)\",\n",
    "        r\"\\?\",\n",
    "    ],\n",
    "    crawl_sample=10000,\n",
    "    log_file_path=LOG_FILE,\n",
    ")\n",
    "print(f\"\\nðŸ“Š Total: {result['total']} URLs\")\n",
    "\n",
    "save_sitemap_urls(sorted(result[\"urls\"]))\n",
    "print(f\"âœ“ Saved to sitemap_urls.txt\")\n",
    "print(f\"âœ“ Log saved to {LOG_FILE}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c0c957d",
   "metadata": {},
   "source": [
    "## Sitemap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "13b3fe8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2 common URL areas with frequency >= 5\n"
     ]
    }
   ],
   "source": [
    "extract_frequent_sitemap_urls(5)\n",
    "extract_url_extensions()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efe84d31",
   "metadata": {},
   "source": [
    "## Exclusion URL Regexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "886b2c0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:neuracrawl_tuner_lib:Extracting URL regexes...\n",
      "INFO:neuracrawl_tuner_lib:Analyzing frequent URL paths...\n",
      "INFO:google_genai.models:AFC is enabled with max remote calls: 10.\n",
      "INFO:neuracrawl_tuner_lib:Found 0 URL regexes.\n",
      "INFO:neuracrawl_tuner_lib:Extracted 0 URL regexes.\n",
      "INFO:neuracrawl_tuner_lib:Applying URL regexes to sitemap URLs...\n",
      "INFO:neuracrawl_tuner_lib:Applied URL regexes. Found 0 excluded and 53 non-excluded URLs.\n",
      "INFO:neuracrawl_tuner_lib:Saved excluded and non-excluded URLs.\n"
     ]
    }
   ],
   "source": [
    "await extract_url_regexes(\n",
    "    \"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63af9296",
   "metadata": {},
   "source": [
    "## Interesting URLs (used to find common content to exclude)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81163e15",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b9df22df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:neuracrawl_tuner_lib:Extracting interesting URLs...\n",
      "INFO:neuracrawl_tuner_lib:Found 53 non-excluded URLs.\n",
      "INFO:neuracrawl_tuner_lib:Processing prompt (1/1)...\n",
      "INFO:google_genai.models:AFC is enabled with max remote calls: 10.\n",
      "INFO:neuracrawl_tuner_lib:Processed prompt (1/1).\n",
      "INFO:neuracrawl_tuner_lib:Summarizing 1 batches...\n",
      "INFO:google_genai.models:AFC is enabled with max remote calls: 10.\n",
      "INFO:neuracrawl_tuner_lib:Summarized 1 batches and found 12 interesting URLs.\n",
      "INFO:neuracrawl_tuner_lib:Extracted 12 interesting URLs.\n"
     ]
    }
   ],
   "source": [
    "await extract_interesting_urls(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8181c409",
   "metadata": {},
   "outputs": [],
   "source": [
    "await download_interesting_urls()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2a1fc1b",
   "metadata": {},
   "source": [
    "## CSS Selectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11406201",
   "metadata": {},
   "outputs": [],
   "source": [
    "await extract_css_selectors(\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8844086a",
   "metadata": {},
   "source": [
    "[] viewer should use save_state.json, maybe only work with save_state.json instead of all the other files? then have a result object that gets plugged into the save_state.json that can include extra data?\n",
    "- better method splitting, service classes, more models for example for counts of file extensions, frequent urls\n",
    "- one file with all kept urls and one with all not kept urls\n",
    "- say with what version we are working when starting sth, like v_000 (latest) or so\n",
    "- auto ai feedback\n",
    "- links are getting bad?\n",
    "- maybe make feedback tab field editable?\n",
    "- <a aria-label=\"Online-Dienst 'Bewohnerparkausweis beantragen / verwalten' starten\" class=\"linklist-boxed__link\" href=\"#\" onclick=\"window.open('https://eservice.siegburg.de/bewohnerparken');return false;\">\n",
    "- remove img and figures\n",
    "- error analysis like look at page xyz, why is this text at the bottom missing, ai gets the text, css selectors and html and markdown and will figure out the exact reason\n",
    "- sitemap deduplizieren mit normalisierung\n",
    "- rendered view of raw html for seeing if it was even in the originial html content of raw html\n",
    "- for downloading the pages juse crawl 4 ai instead of the normal httpx WITH SAME SCROLLING ETC SETTINGS AS IN NEURACRAWL\n",
    "- split up css selector extraction and application to be able to change underlaying interesting urls easily without purging the selectors\n",
    "- exclude by css selector on website\n",
    "- show website urls in the select of xcode app, also at bottom left, not only folder name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2613b26b",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b21be78a",
   "metadata": {},
   "source": [
    "# Manual CSS Selector Application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81704880",
   "metadata": {},
   "outputs": [],
   "source": [
    "apply_css_selectors()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
